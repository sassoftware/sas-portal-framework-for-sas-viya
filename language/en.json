{
  "logOutText": "Logout,",
  "goToViyaText": "Go to SAS Viya",
  "contactMessage": "For information about this page please contact",
  "undefinedObjectText": "This object type is not defined - please check with the administrator.",
  "portalBuilder": {
    "editExistingPages": "Edit an existing page",
    "editSelectPage": "Select the page you want to edit",
    "editDefaultOrder": "Edit the page order",
    "editDefaultOrderHeader": "Edit the current custom page order",
    "createDefaultOrder": "Create a custom page order",
    "createDefaultOrderHeader": "Create a new custom page order",
    "createNewPage": "Create a new page",
    "close": "Close",
    "save": "Save changes",
    "create": "Create",
    "enterPageName": "Enter a name for the portal page",
    "enterPageShorthand": "Enter a shorthand for the portal page (letters only)",
    "enterPageVisible": "Select if the page should be visible",
    "enterPageShowName": "Select if the page name should be shown",
    "enterPageNumCols": "Enter the number of columns on the page",
    "enterPageContact": "Enter an e-mail contact",
    "savePage": "Save page",
    "pageAlreadyExistsAlert": "Error: A page with this name alreay exists. Page names must be unique!",
    "pageCreatedMessage": "The new page was created",
    "invalidName": "Please enter a page name",
    "invalidShorthand": "Please enter a shorthand name",
    "pageUpdatedMessage": "The page was updated"
  },
  "masScore": {
    "moduleSelect": "Please select a MAS Module",
    "stepSelect": "Please select a MAS Module Step",
    "moduleInfo": "View the MAS Module Information",
    "moduleInfoAttribute": "Attribute",
    "moduleInfoValue": "Value",
    "moduleCode": "View the MAS Module Code",
    "moduleCodeClipboard": "Copy Code to Clipboard",
    "stepInputs": "Enter the Inputs to Score the Step",
    "stepOutputs": "Review the Scoring Results",
    "moduleRefresh": "Refresh",
    "moduleScore": "Score",
    "moduleDownloadButton": "Download Content",
    "scoreImportHeader": "Please select a file with the same structure as the module inputs - without headers",
    "scoreRandom": "Score Random Row"
  },
  "computeContextSelectorText": "Please select a Compute Context",
  "clienAdministrator": {
    "oauthClientSelectorText": "Please select a OAuth Client",
    "clientAdminAttribute": "Attribute",
    "clientAdminValue": "Value",
    "oauthClientDownloadButton": "Download Content",
    "oauthClientDefinition": "View the OAuth Client Definition",
    "oauthClientActionText": [
      { "value": "default", "text": "Please choose an action" },
      { "value": "create", "text": "Create a new client" },
      { "value": "update", "text": "Update a client" },
      { "value": "secret", "text": "Update the secret of a client" },
      { "value": "delete", "text": "Delete a client" }
    ],
    "oauthClientActionButton": {
      "default": "Choose Action",
      "create": "Create client",
      "update": "Update client",
      "secret": "Update client secret",
      "delete": "Delete client"
    },
    "oauthClientExplainer": "In the client list there are also many sas.* clients, these are used by SAS Viya itself and should not be changed. <br /> For more information about the different client attributes please read the <a href='https://developer.sas.com/apis/rest/#register-the-client' target='_blank' rel='noopener noreferrer'>SAS documentation</a>.",
    "oauthClientAuthenticatorText1": "For editing/creating the OAuth clients a special token must be generated, click on the following link:",
    "oauthClientAuthenticatorText2": ", assume the administrative group and copy the full URL value into the input field:",
    "oauthClientNoTokenError": "Please enter an authentication token as described above."
  },
  "endToEnd": {
    "mainSearchInput": "Enter your analysis question here...",
    "mainSearchButton": "Analyze",
    "automationCheckboxLabel": "Activate full automation",
    "SASICLINKText": "Review all information in the SAS Viya Information Catalog",
    "attributesHeader": "Attributes (14)",
    "attributesTableHeaders": ["Attribute", "Value"],
    "columnHeaderAccordion": "Columns",
    "columnHeader": ["Column-Names", "Column-Label"],
    "noColumnsFound": "No Columns found - Please run an analysis on the table.",
    "manuelTriggerButton": "Start query with currently selected table",
    "e2eLLMSelectedTableHeader": "The following table was selected by the LLM:",
    "alertMissingColumns": "Please select a table without the No Columsn found note!",
    "mlProjectHeader": "Automated Machine Learning Pipeline runs",
    "mlProjectLink": "Review all details in the SAS Viya Model Studio project",
    "mlpaPublishChampionHeader": "The Champion Model was published",
    "mlpaStepInputs": "Enter the Inputs to Score",
    "mlpaStepOutputs": "Review the Scoring Results",
    "mlpaDownloadButton": "Download",
    "mlpaSubmitButton": "Score",
    "e2eResultTableHeading": "Review Every Step",
    "e2eTableCarouselNote": "Review the relevant tables for your request",
    "LLMSelectedTableStart": "Here are some attributes of the table:",
    "LLMSelectedTableColumnCount": "Number of columns",
    "LLMSelectedTableCompletenessPercent": "Dataset completeness",
    "LLMSelectedTableInformationPrivacy": "Information Privacy status",
    "LLMSelectedTableReviewStatus": "Review status",
    "mlpaSummaryHeading": "Results of the Automated Machine Learning Pipeline Champion Model",
    "STATETOPROGRESSTEXT": {
      "quiesced": "User stopped the modeling process",
      "completed": "The Machine Learning Pipeline run has completed",
      "canceled": "User canceled the modeling process",
      "failed": "The Machine Learning Pipeline run has failed",
      "pending": "Start",
      "preparing": "Gathering resources",
      "waiting": "Updating Metadata & Profiling for Pipeline run",
      "ready": "Ready to start analyzing for optimal Pipeline",
      "modeling": "Feature Engineering, Applying SAS & OS Algorithms, Hyperparameter Optimization",
      "constructingPipeline": "Generating the Pipeline",
      "oversampling": "Using oversampling on the data",
      "runningPipeline": "Pipeline is running - Training Models and Comparing Models",
      "retraining": "The project is retraining"
    }
  },
  "chatWithDataInterfaceText": {
    "chatHeader": "Let's Explore Data",
    "firstQuestion": "What do you want to do?",
    "placeholder": "Type your question...",
    "chooseOption": "Please choose an option: ",
    "searchReport": "Search for Reports",
    "searchData": "Search for Data",
    "selectionChoice": "You selected: ",
    "understandRequest": "Understanding your request...",
    "reportSearch": "Searching for existing reports...",
    "reportDisplay": "Select a Report to display: ",
    "dataSearch": "Searching for data...",
    "dataDisplay": "Select a Table to display: ",
    "dataSelect": "Select a Table to work with: ",
    "recommendATable": "Let the AI decide on the best table...",
    "recommendedTableFound": "A best table has been found: ",
    "createReport": "Creating a new report for you...",
    "reportTitle": "Auto Generated Report for "
  },
  "modelRegistrator": {
    "modelRepositorySelect": "Choose a Model Repository"
  },
  "promptBuilder": {
    "promptBuilderHeading": "LLM Prompt Builder",
    "promptBuilderDescription": "Craft precise and effective prompts for language models. Select from various models and customize their options to optimize performance and achieve the desired outputs. Get started by selecting a model, adjusting the parameters, and entering your prompts.",
    "promptBuilderProjectHeader": "Select or Create a Project that is used for the Prompt Tracking",
    "projectSelect": "Select a Project",
    "promptSelect": "Select an existing Prompt-Test",
    "promptBuilderCreateProject": {
      "modalTitle": "Create a new Project",
      "nameLabel": "Enter the Project Name",
      "descriptionLabel": "Enter the Project Description",
      "closeButtonText": "Close",
      "saveButtonText": "Save"
    },
    "promptBuilderCreatePrompt": {
      "modalTitle": "Create a new Prompt - The new Prompt will be saved into the currently selected project",
      "nameLabel": "Enter the Prompt Name",
      "descriptionLabel": "Enter the Prompt Description",
      "closeButtonText": "Close",
      "saveButtonText": "Save"
    },
    "promptBuilderModelSelectorHeading": "Select the LLMs to test Prompts with",
    "promptBuilderPromptingHeader": "Start building and testing your prompt",
    "promptBuilderSystemPromptPlaceholder": "Enter the system prompt here...",
    "promptBuilderUserPromptPlaceholder": "Enter the user prompt here...",
    "promptBuilderRunExperimentsButton": "Run Experiments",
    "promptBuilderRunExperimentsButtonRunStatus": "Running Experiments...",
    "promptBuilderTemperatureInfo": "Temperature is a parameter that controls the randomness or creativity of the model's responses. It adjusts how the model generates text by affecting the probability distribution of the next word or token in the sequence.<br>Low Temperature (e.g., 0.1 - 0.5): Responses are more deterministic and focused<br>Medium Temperature (e.g., 0.5 - 1.0): Balances between creativity and predictability<br>High Temperature (e.g., 1.0 - 2.0): Responses are more diverse and less predictable",
    "promptBuilderTop_PInfo": "Top-p (also known as nucleus sampling) is a parameter that controls the randomness and creativity of the model's responses by restricting the choice of possible next words or tokens. It influences how the model selects the next word by limiting the probability distribution to a specific subset of words.<br>Low Top-p (e.g., 0.1 - 0.3): The selection is more restricted and focused. Only the most probable words are considered, leading to more deterministic and focused responses<br>Medium Top-p (e.g., 0.4 - 0.7): Provides a balanced mix of creativity and predictability. The range of considered words is broader, allowing the model to include both common and less likely words<br>High Top-p (e.g., 0.8 - 1.0): The selection is broader and less restricted. The model considers a wider range of words, resulting in more creative and less predictable responses",
    "promptBuilderTop_KInfo": "The Top-k parameter changes how the model selects tokens for output. A Top-k of 1 means the selected token is the most probable among all the tokens in the model's vocabulary (also called greedy decoding), while a topK of 3 means that the next token is selected from among the 3 most probable using the temperature. For each token selection step, the topK tokens with the highest probabilities are sampled. Tokens are then further filtered based on Top-p  with the final token selected using temperature sampling.",
    "promptBuilderMax_LengthInfo": "Max_length: This parameter defines the upper boundary for the length of the generated text. Once the model reaches this token limit, it will stop generating further text, even if the completion is not fully finished.",
    "promptExperimentTrackerRunHeader": "Prompt Experiment Run #",
    "promptExperimentTrackerSystemPrompt": "System Prompt:",
    "promptExperimentTrackerUserPrompt": "User Prompt",
    "promptExperimentModel": "Model:",
    "promptExperimentModelOptions": "Model Options:",
    "promptExperimentModelResponse": "Model Response:",
    "promptExperimentModelRunTime": "Time to Response:",
    "promptExperimentModelOutputLength": "Number of Output Tokens:",
    "promptExperimentModelPromptLength": "Number of Input Tokens:",
    "promptExperimentSelectModelsAlert": "You have to select at least one LLM to run an experiment",
    "promptBuilderSaveExperimentsButton": "Save Experiments",
    "promptExperimentSaveModelsPromptAlert": "You have to select Prompt-Test",
    "promptExperimentSaveModelsExperimentAlert": "You have to run at least one experiment",
    "promptBuilderSaveExperimentsButtonStatus": "Saving...",
    "promptExperimentModelPromptBest": "Best Response",
    "promptExperimentSaveSucessResponse": "The experiment has been saved. Here is a link to the prompt: ",
    "promptExperimentSaveFailureResponse": "The experiment couldn't be saved. Please ensure that you have write access to the prompt model in SAS Model Manager.",
    "promptBuilderModelCallFailed": "The model call couldn't be generated please check with the Administrator.",
    "promptBuilderModelInferenceFailed": "The model call failed, please check with the Administrator."
  }
}
